{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446f7063",
   "metadata": {},
   "source": [
    "# Training YOLOv8 for Drowsiness Detection\n",
    "\n",
    "This notebook uses the Simuletic_DMS_Dataset to train a YOLOv8 classification model for detecting drowsiness based on eye state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd73b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbc3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (8.3.232)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (3.9.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.9.1+cpu)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (0.24.1+cpu)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\rig\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: polars>=0.20.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (1.33.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rig\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\rig\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.8.0->ultralytics) (70.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "# Update ultralytics (uncomment if needed)\n",
    "# %pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a0a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.9.1+cpu\n",
      "Uninstalling torch-2.9.1+cpu:\n",
      "  Successfully uninstalled torch-2.9.1+cpu\n",
      "Found existing installation: torchvision 0.24.1+cpu\n",
      "Uninstalling torchvision-0.24.1+cpu:\n",
      "  Successfully uninstalled torchvision-0.24.1+cpu\n",
      "Found existing installation: torchaudio 2.9.1+cpu\n",
      "Uninstalling torchaudio-2.9.1+cpu:\n",
      "  Successfully uninstalled torchaudio-2.9.1+cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Fix torch installation (uncomment if needed)\n",
    "# %pip uninstall torch torchvision torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38b1f04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torch-2.9.1%2Bcpu-cp312-cp312-win_amd64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.1%2Bcpu-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.1%2Bcpu-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rig\\appdata\\roaming\\python\\python312\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\rig\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (70.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rig\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torch-2.9.1%2Bcpu-cp312-cp312-win_amd64.whl (110.9 MB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchvision-0.24.1%2Bcpu-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached https://download.pytorch.org/whl/cpu/torchaudio-2.9.1%2Bcpu-cp312-cp312-win_amd64.whl (663 kB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.9.1+cpu torchaudio-2.9.1+cpu torchvision-0.24.1+cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\RIG\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6182c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Simuletic_DMS_Dataset/labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1569173211.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Load labels and copy images based on eye_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Simuletic_DMS_Dataset/labels'"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "# Define paths\n",
    "dataset_dir = 'Simuletic_DMS_Dataset'\n",
    "images_dir = os.path.join(dataset_dir, 'images')\n",
    "labels_dir = os.path.join(dataset_dir, 'labels')\n",
    "\n",
    "# Create initial directories for classes\n",
    "train_dir = 'train_data'\n",
    "awake_dir = os.path.join(train_dir, 'awake')\n",
    "drowsy_dir = os.path.join(train_dir, 'drowsy')\n",
    "os.makedirs(awake_dir, exist_ok=True)\n",
    "os.makedirs(drowsy_dir, exist_ok=True)\n",
    "\n",
    "# Load labels and copy images based on eye_state\n",
    "for label_file in os.listdir(labels_dir):\n",
    "    if label_file.endswith('.json'):\n",
    "        with open(os.path.join(labels_dir, label_file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "            for sample in data['samples']:\n",
    "                image_name = sample['image']\n",
    "                eye_state = sample['attributes']['eye_state']\n",
    "                src = os.path.join(images_dir, image_name)\n",
    "                if eye_state == 'Open':\n",
    "                    dst = os.path.join(awake_dir, image_name)\n",
    "                elif eye_state == 'Closed':\n",
    "                    dst = os.path.join(drowsy_dir, image_name)\n",
    "                else:\n",
    "                    continue\n",
    "                if os.path.exists(src):\n",
    "                    shutil.copy(src, dst)\n",
    "\n",
    "print(\"Dataset prepared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfa954eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into train and val.\n"
     ]
    }
   ],
   "source": [
    "# Split into train and val sets\n",
    "random.seed(42)  # For reproducibility\n",
    "\n",
    "# Define subdirectories for train and val\n",
    "train_awake_dir = os.path.join(train_dir, 'train', 'awake')\n",
    "train_drowsy_dir = os.path.join(train_dir, 'train', 'drowsy')\n",
    "val_awake_dir = os.path.join(train_dir, 'val', 'awake')\n",
    "val_drowsy_dir = os.path.join(train_dir, 'val', 'drowsy')\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [train_awake_dir, train_drowsy_dir, val_awake_dir, val_drowsy_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "# Split each class: 80% train, 20% val\n",
    "for class_dir, train_class_dir, val_class_dir in [(awake_dir, train_awake_dir, val_awake_dir), (drowsy_dir, train_drowsy_dir, val_drowsy_dir)]:\n",
    "    images = os.listdir(class_dir)\n",
    "    random.shuffle(images)\n",
    "    split_idx = int(0.8 * len(images))\n",
    "    train_images = images[:split_idx]\n",
    "    val_images = images[split_idx:]\n",
    "    for img in train_images:\n",
    "        shutil.move(os.path.join(class_dir, img), os.path.join(train_class_dir, img))\n",
    "    for img in val_images:\n",
    "        shutil.move(os.path.join(class_dir, img), os.path.join(val_class_dir, img))\n",
    "    os.rmdir(class_dir)  # Remove empty original dir\n",
    "\n",
    "print(\"Dataset split into train and val.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f59b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.232 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.199  Python-3.12.5 torch-2.7.0+cpu CPU (Intel Core i5-5300U 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=train_data, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=D:\\Clout\\Drowsiness-Detection-with-YOLOv8\\runs\\classify\\train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m D:\\Clout\\Drowsiness-Detection-with-YOLOv8\\train_data\\train... found 113 images in 2 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m D:\\Clout\\Drowsiness-Detection-with-YOLOv8\\train_data\\val... found 30 images in 2 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1.90.4 MB/s, size: 38.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Clout\\Drowsiness-Detection-with-YOLOv8\\train_data\\train\\awake.cache... 0 images, 113 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 113/113 56.5Kit/s 0.0s\n",
      "WARNING Labels are missing or empty in D:\\Clout\\Drowsiness-Detection-with-YOLOv8\\train_data\\train\\awake.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.40.5 ms, read: 1.81.0 MB/s, size: 41.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Clout\\Drowsiness-Detection-with-YOLOv8\\train_data\\val\\awake.cache... 0 images, 30 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 30/30 15.0Kit/s 0.0s\n",
      "WARNING Labels are missing or empty in D:\\Clout\\Drowsiness-Detection-with-YOLOv8\\train_data\\val\\awake.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train YOLOv8 classification model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO()  \u001b[38;5;66;03m# Create a new model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassify\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\model.py:800\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune\u001b[39m(\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    784\u001b[0m     use_ray\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    788\u001b[0m ):\n\u001b[0;32m    789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Conduct hyperparameter tuning for the model, with an option to use Ray Tune.\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \n\u001b[0;32m    791\u001b[0m \u001b[38;5;124;03m    This method supports two modes of hyperparameter tuning: using Ray Tune or a custom tuning method. When Ray Tune\u001b[39;00m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;124;03m    is enabled, it leverages the 'run_ray_tune' function from the ultralytics.utils.tuner module. Otherwise, it uses\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;124;03m    the internal 'Tuner' class for tuning. The method combines default, overridden, and custom arguments to\u001b[39;00m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;124;03m    configure the tuning process.\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \n\u001b[0;32m    796\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;124;03m        use_ray (bool): Whether to use Ray Tune for hyperparameter tuning. If False, uses internal tuning method.\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;124;03m        iterations (int): Number of tuning iterations to perform.\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;124;03m        *args (Any): Additional positional arguments to pass to the tuner.\u001b[39;00m\n\u001b[1;32m--> 800\u001b[0m \u001b[38;5;124;03m        **kwargs (Any): Additional keyword arguments for tuning configuration. These are combined with model\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124;03m            overrides and defaults to configure the tuning process.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[0;32m    803\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;124;03m        (dict): Results of the hyperparameter search, including best parameters and performance metrics.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[0;32m    806\u001b[0m \u001b[38;5;124;03m    Raises:\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;124;03m        TypeError: If the model is not a PyTorch model.\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \n\u001b[0;32m    809\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03m        >>> model = YOLO(\"yolo11n.pt\")\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03m        >>> results = model.tune(data=\"coco8.yaml\", iterations=5)\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m        >>> print(results)\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \n\u001b[0;32m    814\u001b[0m \u001b[38;5;124;03m        # Use Ray Tune for more advanced hyperparameter search\u001b[39;00m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;124;03m        >>> results = model.tune(use_ray=True, iterations=20, data=\"coco8.yaml\")\u001b[39;00m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_is_pytorch_model()\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_ray:\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:231\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:357\u001b[0m, in \u001b[0;36m_do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpatience), \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_training(ckpt)\n\u001b[1;32m--> 357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mlast_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# do not move\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_pretrain_routine_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:327\u001b[0m, in \u001b[0;36m_setup_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39mbatch_size, rank\u001b[38;5;241m=\u001b[39mLOCAL_RANK, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m )\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    329\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    330\u001b[0m     rank\u001b[38;5;241m=\u001b[39mLOCAL_RANK,\n\u001b[0;32m    331\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    332\u001b[0m )\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_validator()\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m ModelEMA(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\train.py:172\u001b[0m, in \u001b[0;36mget_validator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlabel_loss_items\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss_items: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, prefix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a loss dict with labeled training loss items tensor.\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m \n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m        loss_items (list[float], optional): List of loss values.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m        prefix (str): Prefix for keys in the returned dictionary.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m        (dict | list): Dictionary of labeled loss items if loss_items is provided, otherwise list of keys.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_names]\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss_items \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\models\\yolo\\detect\\val.py:55\u001b[0m, in \u001b[0;36mDetectionValidator.__init__\u001b[1;34m(self, dataloader, save_dir, args, _callbacks)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize detection validator with necessary variables and settings.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    _callbacks (list[Any], optional): List of callback functions.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(dataloader, save_dir, args, _callbacks)\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_coco \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_lvis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ultralytics\\engine\\validator.py:104\u001b[0m, in \u001b[0;36mBaseValidator.__init__\u001b[1;34m(self, dataloader, save_dir, args, _callbacks)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\_meta_registrations.py:25\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fn\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mroi_align\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\RIG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\_meta_registrations.py:18\u001b[0m, in \u001b[0;36mregister_meta.<locals>.wrapper\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(fn):\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[38;5;241m.\u001b[39m_has_ops():\n\u001b[0;32m     19\u001b[0m         get_meta_lib()\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mtorchvision, op_name), overload_name), fn)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# Train YOLOv8 classification model\n",
    "# Create a new YOLO model for classification\n",
    "model = YOLO()  # Defaults to classification if task specified\n",
    "# Train with specified parameters\n",
    "results = model.train(task='classify', data=train_dir, epochs=10, imgsz=224)\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b9ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Display training results\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop-1 Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresults\u001b[49m\u001b[38;5;241m.\u001b[39mresults_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics/accuracy_top1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop-5 Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39mresults_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics/accuracy_top5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39mresults_dict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics/precision\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# Display training results\n",
    "print(\"Training Results:\")\n",
    "if hasattr(results, 'results_dict') and results.results_dict:\n",
    "    metrics = results.results_dict\n",
    "    print(f\"Top-1 Accuracy: {metrics.get('metrics/accuracy_top1', 'N/A')}\")\n",
    "    print(f\"Top-5 Accuracy: {metrics.get('metrics/accuracy_top5', 'N/A')}\")\n",
    "    print(f\"Precision: {metrics.get('metrics/precision(B)', 'N/A')}\")\n",
    "    print(f\"Recall: {metrics.get('metrics/recall(B)', 'N/A')}\")\n",
    "    print(f\"F1 Score: {metrics.get('metrics/f1(B)', 'N/A')}\")\n",
    "else:\n",
    "    print(\"Metrics not available. Check results object.\")\n",
    "\n",
    "# Plot results if available\n",
    "try:\n",
    "    if hasattr(results, 'plots'):\n",
    "        results.plots()\n",
    "except Exception as e:\n",
    "    print(f\"Plotting failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fcab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('drowsiness_model.pt')\n",
    "print(\"Model saved as drowsiness_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e082238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on sample images\n",
    "# Test on awake image\n",
    "test_image_awake = os.path.join(train_awake_dir, os.listdir(train_awake_dir)[0])\n",
    "results_awake = model.predict(test_image_awake)\n",
    "print(f\"Prediction for awake image: {results_awake[0].probs.top1} (confidence {results_awake[0].probs.top1conf:.2f})\")\n",
    "\n",
    "# Test on drowsy image\n",
    "test_image_drowsy = os.path.join(train_drowsy_dir, os.listdir(train_drowsy_dir)[0])\n",
    "results_drowsy = model.predict(test_image_drowsy)\n",
    "print(f\"Prediction for drowsy image: {results_drowsy[0].probs.top1} (confidence {results_drowsy[0].probs.top1conf:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89274f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on awake image\n",
    "test_image_awake = os.path.join(train_awake_dir, os.listdir(train_awake_dir)[0])\n",
    "results_awake = model.predict(test_image_awake)\n",
    "print(f\"Prediction for awake image: {results_awake[0].probs.top1} (class {results_awake[0].probs.top1conf:.2f})\")\n",
    "\n",
    "# Test on drowsy image\n",
    "test_image_drowsy = os.path.join(train_drowsy_dir, os.listdir(train_drowsy_dir)[0])\n",
    "results_drowsy = model.predict(test_image_drowsy)\n",
    "print(f\"Prediction for drowsy image: {results_drowsy[0].probs.top1} (class {results_drowsy[0].probs.top1conf:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
